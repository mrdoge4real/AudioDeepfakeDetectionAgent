# -*- coding: utf-8 -*-
import os
import json
import sys
import numpy as np
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

BASE_DIR = os.getenv("BASE_DIR")

sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

SUSPICIOUS_FEATURE_ROOT = os.path.join(BASE_DIR, "outputs", "suspicious_features")
ASR_OUTPUT_ROOT = os.path.join(BASE_DIR, "outputs", "asr")
REFERENCE_OUTPUT_ROOT = os.path.join(BASE_DIR, "outputs", "reference_report")
os.makedirs(REFERENCE_OUTPUT_ROOT, exist_ok=True)

ANOMALY_THRESHOLDS = {
    "mfcc_mean_abs": 0.5,
    "mfcc_std_upper": 35.0141,
    "mfcc_inner_std_upper": 44.6855,
    "mel_energy_upper": -43.5002,
    "mel_energy_lower": -65.9447,
    "high_risk_anomaly_count": 2,
    "medium_risk_anomaly_count": 1
}

def load_asr_diarization_data(audio_filename):
    asr_json_path = os.path.join(ASR_OUTPUT_ROOT, f"{audio_filename}_asr_diarization.json")
    
    if not os.path.exists(asr_json_path):
        print(f"â„¹ï¸ æœªæ‰¾åˆ°{audio_filename}çš„ASR+è¯´è¯äººæ•°æ®ï¼š{asr_json_path}")
        return None
    
    try:
        with open(asr_json_path, "r", encoding="utf-8") as f:
            asr_data = json.load(f)
        
        if not asr_data.get("success"):
            print(f"â„¹ï¸ {audio_filename}çš„ASRæ•°æ®æ— æ•ˆï¼š{asr_data.get('error')}")
            return None
        
        return asr_data
    except Exception as e:
        print(f"â„¹ï¸ è§£æASRæ•°æ®å¤±è´¥ï¼š{str(e)}")
        return None

def match_suspicious_segment_with_text(suspicious_segment, asr_segments):
    seg_start = suspicious_segment["start"]
    seg_end = suspicious_segment["end"]
    matched_words = []
    
    for word_seg in asr_segments:
        word_start = word_seg["start"]
        word_end = word_seg["end"]
        
        if not (word_end < seg_start or word_start > seg_end):
            matched_words.append({
                "speaker_id": word_seg["speaker_id"],
                "word": word_seg["word"],
                "start": word_seg["start"],
                "end": word_seg["end"]
            })
    
    matched_text = " ".join([w["word"] for w in matched_words])
    return {
        "matched_words": matched_words,
        "matched_text": matched_text,
        "total_matched_words": len(matched_words),
        "speakers_in_segment": list(set([w["speaker_id"] for w in matched_words]))
    }

def load_suspicious_features(audio_filename):
    summary_path = os.path.join(SUSPICIOUS_FEATURE_ROOT, audio_filename, "suspicious_features_summary.json")
    
    if not os.path.exists(summary_path):
        return {
            "success": False,
            "error": f"å¯ç–‘ç‰‡æ®µç‰¹å¾æ±‡æ€»æ–‡ä»¶ä¸å­˜åœ¨ï¼š{summary_path}"
        }
    
    try:
        with open(summary_path, "r", encoding="utf-8") as f:
            feature_data = json.load(f)
        
        if not feature_data.get("success"):
            return {
                "success": False,
                "error": f"ç‰¹å¾æå–å¤±è´¥ï¼Œæ±‡æ€»æ–‡ä»¶æ ‡è®°ä¸ºå¤±è´¥çŠ¶æ€"
            }
        
        return {
            "success": True,
            "data": feature_data
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"è§£æç‰¹å¾æ–‡ä»¶å¤±è´¥ï¼š{str(e)}"
        }

def analyze_feature_anomaly(segment_feature, asr_data=None):
    analysis_lines = []
    segment_id = segment_feature["segment_id"]
    time_range = segment_feature["time_range"]
    time_str = f"{time_range['start']}s - {time_range['end']}s"

    analysis_lines.append(f"### ç‰‡æ®µ{segment_id}ï¼ˆæ—¶é—´èŒƒå›´ï¼š{time_str}ï¼‰")

    if asr_data and asr_data.get("segments"):
        match_result = match_suspicious_segment_with_text(time_range, asr_data["segments"])
        analysis_lines.append(f"- **è¯­éŸ³å†…å®¹**ï¼š{match_result['matched_text'] or 'æ— åŒ¹é…å†…å®¹'}")
        analysis_lines.append(f"- **è¯´è¯äºº**ï¼š{', '.join(match_result['speakers_in_segment']) or 'UNKNOWN'}")
        analysis_lines.append(f"- **åŒ¹é…è¯æ•°**ï¼š{match_result['total_matched_words']}")
    else:
        analysis_lines.append(f"- **è¯­éŸ³å†…å®¹**ï¼šæœªè·å–åˆ°ASRæ•°æ®")
        analysis_lines.append(f"- **è¯´è¯äºº**ï¼šæœªè·å–åˆ°è¯´è¯äººæ•°æ®")
    
    analysis_lines.append("")

    mfcc_feature = segment_feature["mfcc_feature"]
    if mfcc_feature["success"]:
        mfcc_stats = mfcc_feature["mfcc_stats"]
        mfcc_mean_abs = abs(mfcc_stats["mean"])
        mfcc_std = mfcc_stats["std"]
        
        mfcc_analysis = []
        if mfcc_mean_abs > ANOMALY_THRESHOLDS["mfcc_mean_abs"]:
            mfcc_analysis.append(f"MFCCå‡å€¼ç»å¯¹å€¼({round(mfcc_mean_abs, 3)})è¶…å‡ºæ­£å¸¸èŒƒå›´ï¼ˆâ‰¤{ANOMALY_THRESHOLDS['mfcc_mean_abs']}ï¼‰")
        if mfcc_std > ANOMALY_THRESHOLDS["mfcc_std_upper"]:
            mfcc_analysis.append(f"MFCCæ•´ä½“æ ‡å‡†å·®({round(mfcc_std, 3)})è¶…å‡ºçœŸäººè¯­éŸ³åŸºå‡†ï¼ˆâ‰¤{ANOMALY_THRESHOLDS['mfcc_std_upper']}ï¼‰ï¼Œé¢‘è°±æ³¢åŠ¨å¼‚å¸¸ï¼ˆåˆæˆéŸ³é¢‘å…¸å‹ç‰¹å¾ï¼‰")
        
        if mfcc_analysis:
            analysis_lines.append(f"- **MFCCç‰¹å¾å¼‚å¸¸**ï¼š{'; '.join(mfcc_analysis)}ï¼›")
        else:
            analysis_lines.append(f"- **MFCCç‰¹å¾**ï¼šå‡å€¼ç»å¯¹å€¼({round(mfcc_mean_abs, 3)})ã€æ•´ä½“æ ‡å‡†å·®({round(mfcc_std, 3)})å‡ç¬¦åˆçœŸäººè¯­éŸ³åŸºå‡†ï¼›")
    else:
        analysis_lines.append(f"- **MFCCç‰¹å¾**ï¼šæå–å¤±è´¥ â†’ {mfcc_feature.get('error', 'æœªçŸ¥é”™è¯¯')}ï¼›")

    mel_feature = segment_feature["mel_feature"]
    if mel_feature["success"]:
        mel_stats = mel_feature["mel_energy_stats"]
        mel_mean = mel_stats["mean"]
        
        mel_analysis = []
        if mel_mean > ANOMALY_THRESHOLDS["mel_energy_upper"]:
            mel_analysis.append(f"æ¢…å°”èƒ½é‡å‡å€¼({round(mel_mean, 1)}dB)åé«˜ï¼ˆæ­£å¸¸â‰¤{ANOMALY_THRESHOLDS['mel_energy_upper']}dBï¼‰ï¼Œé¢‘åŸŸèƒ½é‡åˆ†å¸ƒå¼‚å¸¸")
        elif mel_mean < ANOMALY_THRESHOLDS["mel_energy_lower"]:
            mel_analysis.append(f"æ¢…å°”èƒ½é‡å‡å€¼({round(mel_mean, 1)}dB)åä½ï¼ˆæ­£å¸¸â‰¥{ANOMALY_THRESHOLDS['mel_energy_lower']}dBï¼‰ï¼Œé«˜é¢‘ä¿¡æ¯ç¼ºå¤±ï¼ˆåˆæˆéŸ³é¢‘å…¸å‹ç‰¹å¾ï¼‰")
        
        if mel_analysis:
            analysis_lines.append(f"- **æ¢…å°”é¢‘è°±ç‰¹å¾å¼‚å¸¸**ï¼š{'; '.join(mel_analysis)}ï¼›")
        else:
            analysis_lines.append(f"- **æ¢…å°”é¢‘è°±ç‰¹å¾**ï¼šèƒ½é‡å‡å€¼({round(mel_mean, 1)}dB)ç¬¦åˆçœŸäººè¯­éŸ³åŸºå‡†ï¼ˆ{ANOMALY_THRESHOLDS['mel_energy_lower']}~{ANOMALY_THRESHOLDS['mel_energy_upper']}dBï¼‰ï¼›")
    else:
        analysis_lines.append(f"- **æ¢…å°”é¢‘è°±ç‰¹å¾**ï¼šæå–å¤±è´¥ â†’ {mel_feature.get('error', 'æœªçŸ¥é”™è¯¯')}ï¼›")

    return "\n".join(analysis_lines)

def generate_reference_report(audio_filename):
    feature_result = load_suspicious_features(audio_filename)
    if not feature_result["success"]:
        print(f"âŒ {feature_result['error']}")
        return feature_result
    
    feature_data = feature_result["data"]
    total_segments = feature_data["total_suspicious_segments"]
    extracted_segments = feature_data["extracted_segments_count"]
    audio_path = feature_data["audio_path"]

    asr_data = load_asr_diarization_data(audio_filename)

    report_content = []
    report_content.append(f"# éŸ³é¢‘ä¼ªé€ æ£€æµ‹åˆ†ææŠ¥å‘Š")
    report_content.append(f"## åŸºç¡€ä¿¡æ¯")
    report_content.append(f"- è¯­éŸ³æ–‡ä»¶æ ‡è¯†ï¼š{audio_filename}")
    report_content.append(f"- åŸå§‹éŸ³é¢‘è·¯å¾„ï¼š{audio_path}")
    report_content.append(f"- æ£€æµ‹åˆ°çš„å¯ç–‘ç‰‡æ®µæ€»æ•°ï¼š{total_segments}")
    report_content.append(f"- æˆåŠŸæå–ç‰¹å¾çš„ç‰‡æ®µæ•°ï¼š{extracted_segments}")
    report_content.append(f"- å¼‚å¸¸åˆ¤å®šåŸºå‡†ï¼šLibriSpeech dev-clean 500æ¡çœŸäººè¯­éŸ³ç»Ÿè®¡ï¼ˆ3ÏƒåŸåˆ™ï¼‰")

    if asr_data:
        report_content.append(f"- è¯­éŸ³è¯†åˆ«è¯­è¨€ï¼š{asr_data.get('language', 'æœªçŸ¥')}")
        report_content.append(f"- éŸ³é¢‘æ€»æ—¶é•¿ï¼š{asr_data.get('audio_duration', 'æœªçŸ¥')} ç§’")
        report_content.append(f"- è¯†åˆ«æ€»è¯æ•°ï¼š{asr_data.get('total_words', 0)}")
        report_content.append(f"- æ£€æµ‹åˆ°çš„è¯´è¯äººæ•°é‡ï¼š{asr_data.get('total_speakers', 0)}")
        report_content.append(f"- å®Œæ•´è¯­éŸ³å†…å®¹ï¼š{asr_data.get('full_text', 'æ— ')}")
    else:
        report_content.append(f"- è¯­éŸ³è¯†åˆ«çŠ¶æ€ï¼šæœªè·å–åˆ°ASR+è¯´è¯äººæ•°æ®")

    report_content.append(f"\n## å¯ç–‘ç‰‡æ®µç‰¹å¾+è¯­éŸ³å†…å®¹åˆ†æ")

    if extracted_segments == 0:
        report_content.append(f"> æœªæ£€æµ‹åˆ°ä»»ä½•å¯ç–‘ç‰‡æ®µï¼Œè¯¥éŸ³é¢‘æ— ä¼ªé€ é£é™©ã€‚")
    else:
        for segment_feature in feature_data["segments_features"]:
            anomaly_analysis = analyze_feature_anomaly(segment_feature, asr_data)
            report_content.append(anomaly_analysis)
            report_content.append("")
        
        report_content.append(f"\n## æ•´ä½“é£é™©è¯„ä¼°")
        has_anomaly = False
        anomaly_details = []
        
        for seg in feature_data["segments_features"]:
            mfcc = seg.get("mfcc_feature", {})
            if mfcc.get("success"):
                mfcc_mean_abs = abs(mfcc["mfcc_stats"]["mean"])
                mfcc_std = mfcc["mfcc_stats"]["std"]
                if mfcc_mean_abs > ANOMALY_THRESHOLDS["mfcc_mean_abs"]:
                    has_anomaly = True
                    anomaly_details.append(f"ç‰‡æ®µ{seg['segment_id']}MFCCå‡å€¼å¼‚å¸¸")
                if mfcc_std > ANOMALY_THRESHOLDS["mfcc_std_upper"]:
                    has_anomaly = True
                    anomaly_details.append(f"ç‰‡æ®µ{seg['segment_id']}MFCCæ ‡å‡†å·®å¼‚å¸¸")
            
            mel = seg.get("mel_feature", {})
            if mel.get("success"):
                mel_mean = mel["mel_energy_stats"]["mean"]
                if mel_mean > ANOMALY_THRESHOLDS["mel_energy_upper"] or mel_mean < ANOMALY_THRESHOLDS["mel_energy_lower"]:
                    has_anomaly = True
                    anomaly_details.append(f"ç‰‡æ®µ{seg['segment_id']}æ¢…å°”èƒ½é‡å¼‚å¸¸")
        
        if has_anomaly:
            report_content.append(f"> âš ï¸ æ£€æµ‹åˆ°ä»¥ä¸‹å¼‚å¸¸ï¼š{'; '.join(anomaly_details)}ï¼›è¯¥éŸ³é¢‘**å­˜åœ¨ä¼ªé€ é£é™©**ã€‚")
            if asr_data:
                report_content.append(f"> ğŸ“¢ å¼‚å¸¸ç‰‡æ®µå¯¹åº”çš„è¯­éŸ³å†…å®¹å·²æ ‡æ³¨ï¼Œå¯ç»“åˆè¯­ä¹‰è¿›ä¸€æ­¥éªŒè¯ä¼ªé€ é£é™©ã€‚")
        else:
            report_content.append(f"> âœ… æ‰€æœ‰ç‰‡æ®µç‰¹å¾å‡ç¬¦åˆLibriSpeechçœŸäººè¯­éŸ³åŸºå‡†ï¼Œè¯¥éŸ³é¢‘**ä¼ªé€ é£é™©è¾ƒä½**ã€‚")

    report_filename = f"{audio_filename}_fake_detection_report.md"
    if not os.path.exists(REFERENCE_OUTPUT_ROOT):
        try:
            os.makedirs(REFERENCE_OUTPUT_ROOT, mode=0o755)
            print(f"âœ… åˆ›å»ºç›®å½•æˆåŠŸï¼š{REFERENCE_OUTPUT_ROOT}")
        except Exception as e:
            return {
                "success": False,
                "error": f"åˆ›å»ºæŠ¥å‘Šç›®å½•å¤±è´¥ï¼š{str(e)}ï¼ˆæƒé™ä¸è¶³ï¼Ÿï¼‰"
            }
    report_path = os.path.abspath(os.path.join(REFERENCE_OUTPUT_ROOT, report_filename))
    try:
        with open(report_path, "w", encoding="utf-8") as f:
            f.write("\n".join(report_content))
        if os.path.exists(report_path):
            print(f"âœ… MDæ–‡ä»¶ç”ŸæˆæˆåŠŸï¼š{report_path}")
            print(f"âœ… æ–‡ä»¶å¤§å°ï¼š{os.path.getsize(report_path)} å­—èŠ‚")
            return {
                "success": True,
                "audio_filename": audio_filename,
                "report_path": report_path,
                "message": f"åˆ†ææŠ¥å‘Šå·²æˆåŠŸç”Ÿæˆï¼š{report_path}"
            }
        else:
            return {
                "success": False,
                "error": f"æ–‡ä»¶å†™å…¥åä¸å­˜åœ¨ï¼Œå¯èƒ½æ˜¯æƒé™é—®é¢˜ï¼š{report_path}"
            }
    except PermissionError:
        return {
            "success": False,
            "error": f"æ— å†™å…¥æƒé™ï¼š{report_path}ï¼ˆè¯·æ£€æŸ¥ç›®å½•æƒé™ï¼‰"
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"ä¿å­˜åˆ†ææŠ¥å‘Šå¤±è´¥ï¼š{str(e)}"
        }

if __name__ == "__main__":
    test_audio_filename = "LA_E_1000147"
    result = generate_reference_report(test_audio_filename)
    
    if result["success"]:
        print(f"âœ… {result['message']}")
    else:
        print(f"âŒ {result['error']}")

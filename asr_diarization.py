import os
import json
import librosa
import whisper
import torch
from pathlib import Path
from dotenv import load_dotenv
from pyannote.audio import Pipeline
# æ–°å¢ï¼šå¯¼å…¥ListConfigç”¨äºå®‰å…¨åˆ—è¡¨é…ç½®
from omegaconf.listconfig import ListConfig

# ====================== 1. åŠ è½½.envé…ç½®ï¼ˆæ ¸å¿ƒï¼‰ ======================
# åŠ è½½.envæ–‡ä»¶ï¼ˆä¼˜å…ˆä»è„šæœ¬æ‰€åœ¨ç›®å½•æ‰¾ï¼Œæ‰¾ä¸åˆ°åˆ™ä»é¡¹ç›®æ ¹ç›®å½•æ‰¾ï¼‰
load_dotenv()

# ä».envè¯»å–é¡¹ç›®æ ¹ç›®å½•ï¼Œè®¾ç½®å…œåº•å€¼ï¼ˆåŠ¨æ€æ¨å¯¼ï¼‰
BASE_DIR = os.getenv("BASE_DIR") or str(Path(__file__).resolve().parent.parent)
# ä».envè¯»å–HF_TOKENï¼ˆpyannoteæ¨¡å‹éœ€è¦è®¤è¯ï¼‰
HF_TOKEN = os.getenv("HF_TOKEN", "")

# ====================== å…¨å±€é…ç½®ï¼ˆè·¨å¹³å°+å¯¹é½åˆ†å¸ƒå¼æ¶æ„ï¼‰ ======================
# ASRç»“æœè¾“å‡ºæ ¹ç›®å½•ï¼ˆåŸºäº.envçš„BASE_DIRï¼Œè·¨å¹³å°å…¼å®¹ï¼‰
ASR_OUTPUT_ROOT = Path(BASE_DIR) / "outputs" / "asr"
ASR_OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºå¤šçº§ç›®å½•
ASR_OUTPUT_ROOT = str(ASR_OUTPUT_ROOT)  # è½¬ä¸ºå­—ç¬¦ä¸²å…¼å®¹osæ¨¡å—

# ====================== å…³é”®ä¿®å¤ï¼šPyTorch 2.6 å…¼å®¹æ€§é…ç½® ======================
# 1. å°†ListConfigåŠ å…¥PyTorchå®‰å…¨å…¨å±€åˆ—è¡¨ï¼Œå…è®¸åŠ è½½è¯¥ç±»å‹
torch.serialization.add_safe_globals([ListConfig])

# 2. å¼ºåˆ¶å¯ç”¨torch.loadè¡¥ä¸ï¼ˆè§£å†³weights_onlyé—®é¢˜ï¼Œå¿…å¼€ï¼‰
def patch_torch_load():
    original_load = torch.load
    def patched_load(*args, **kwargs):
        kwargs["weights_only"] = False  # å¼ºåˆ¶å…³é—­å®‰å…¨æ£€æŸ¥
        return original_load(*args, **kwargs)
    torch.load = patched_load

# æ‰§è¡Œè¡¥ä¸ï¼ˆå¿…é¡»å¯ç”¨ï¼Œå¦åˆ™ä»ä¼šæŠ¥é”™ï¼‰
patch_torch_load()

# ====================== å·¥å…·å‡½æ•°ï¼šæå–éŸ³é¢‘æ–‡ä»¶åï¼ˆå»åç¼€ï¼Œè·¨å¹³å°ï¼‰ ======================
def extract_audio_filename(audio_path):
    """
    è·¨å¹³å°æå–éŸ³é¢‘æ–‡ä»¶åï¼ˆå»åç¼€ï¼‰ï¼Œå…¼å®¹Linux/Windowsè·¯å¾„
    ç¤ºä¾‹ï¼š
    - /home/bowen/audio/standard_audio/LA_E_1000147.wav â†’ LA_E_1000147
    - E:/audio/standard_audio/test.wav â†’ test
    - ./my_audio.wav â†’ my_audio
    """
    filename = Path(audio_path).stem
    return filename

# ====================== æ ¸å¿ƒå‡½æ•°ï¼šASR + è¯´è¯äººåˆ†å‰²ï¼ˆå¯¹é½æ–‡ä»¶å+è·¨å¹³å°ï¼‰ ======================
def extract_asr_with_speaker_diarization(
    audio_path: str,
    whisper_model_size: str = "base",
    save_json: bool = True
):
    """
    Whisper ASR + pyannote Speaker Diarization
    æ ¸å¿ƒä¼˜åŒ–ï¼šå…¼å®¹PyTorch 2.6 + pyannoteè®¤è¯ + è·¨å¹³å°è·¯å¾„
    """
    # è·¨å¹³å°æ ‡å‡†åŒ–è¾“å…¥è·¯å¾„
    audio_path = Path(audio_path).resolve()
    audio_filename = extract_audio_filename(audio_path)
    audio_path_str = str(audio_path)

    if not audio_path.exists():
        result = {
            "success": False,
            "audio_filename": audio_filename,
            "error": f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼š{audio_path_str}",
            "segments": None
        }
        if save_json:
            save_asr_result(result, audio_filename)
        return json.dumps(result, ensure_ascii=False, indent=2)

    try:
        # ========= 1. éŸ³é¢‘æ ¡éªŒ =========
        audio, sr = librosa.load(audio_path_str, sr=16000, mono=True)
        if sr != 16000:
            raise ValueError(f"é‡‡æ ·ç‡é”™è¯¯ï¼š{sr}Hzï¼ˆå¿…é¡»ä¸º 16kHzï¼‰")
        duration = librosa.get_duration(y=audio, sr=sr)

        # ========= 2. Whisper ASR =========
        # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼ˆCUDAå¯ç”¨åˆ™ç”¨GPUï¼Œå¦åˆ™CPUï¼‰
        device = "cuda" if torch.cuda.is_available() else "cpu"
        whisper_model = whisper.load_model(whisper_model_size, device=device)
        asr_result = whisper_model.transcribe(
            audio_path_str,
            language="en",
            task="transcribe",
            word_timestamps=True,
            verbose=False
        )

        # æå–å•è¯çº§æ—¶é—´æˆ³
        words = []
        for seg in asr_result.get("segments", []):
            for w in seg.get("words", []):
                words.append({
                    "word": w["word"].strip(),
                    "start": float(w["start"]),
                    "end": float(w["end"])
                })

        # ========= 3. Speaker Diarizationï¼ˆæ ¸å¿ƒä¿®å¤ï¼šç§»é™¤deviceå‚æ•°ï¼‰ =========
        diarization_pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization",
        )

        diarization = diarization_pipeline(audio_path)

        speaker_segments = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            speaker_segments.append({
                "speaker_id": speaker,
                "start": float(turn.start),
                "end": float(turn.end)
            })


        # ========= 4. è¯ â†” è¯´è¯äºº å¯¹é½ =========
        aligned_words = []
        for w in words:
            mid_time = (w["start"] + w["end"]) / 2.0
            speaker_id = "UNKNOWN"
            for seg in speaker_segments:
                if seg["start"] <= mid_time <= seg["end"]:
                    speaker_id = seg["speaker_id"]
                    break
            aligned_words.append({
                "speaker_id": speaker_id,
                "word": w["word"],
                "start": round(w["start"], 3),
                "end": round(w["end"], 3)
            })

        # ========= 5. æ„é€ ç»“æœ =========
        result = {
            "success": True,
            "audio_filename": audio_filename,
            "error": None,
            "language": "en",
            "full_text": asr_result.get("text", "").strip(),
            "segments": aligned_words,
            "total_words": len(aligned_words),
            "total_speakers": len(set(w["speaker_id"] for w in aligned_words)),
            "audio_path": audio_path_str,
            "audio_duration": round(duration, 2),
            "device_used": device  # æ–°å¢ï¼šè®°å½•ä½¿ç”¨çš„è®¾å¤‡
        }

        # ========= 6. ä¿å­˜ç»“æœ =========
        if save_json:
            save_asr_result(result, audio_filename)

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        # è¯¦ç»†æ‰“å°é”™è¯¯æ ˆï¼Œæ–¹ä¾¿æ’æŸ¥
        import traceback
        error_detail = traceback.format_exc()
        result = {
            "success": False,
            "audio_filename": audio_filename,
            "error": f"ASR + è¯´è¯äººåˆ†ç¦»å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†é”™è¯¯ï¼š{error_detail}",
            "segments": None,
            "audio_path": audio_path_str
        }
        if save_json:
            save_asr_result(result, audio_filename)
        return json.dumps(result, ensure_ascii=False, indent=2)

# ====================== å·¥å…·å‡½æ•°ï¼šä¿å­˜ASRç»“æœ ======================
def save_asr_result(result, audio_filename):
    """æŒ‰æ–‡ä»¶åä¿å­˜ASRç»“æœï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰"""
    json_filename = f"{audio_filename}_asr_diarization.json"
    json_path = str(Path(ASR_OUTPUT_ROOT) / json_filename)
    
    try:
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ ASRç»“æœå·²ä¿å­˜ï¼š{json_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜ASR JSONå¤±è´¥ï¼š{str(e)}")

# ====================== æ‰¹é‡å¤„ç†å‡½æ•° ======================
def batch_process_standard_audio(audio_dir: str = None):
    """æ‰¹é‡å¤„ç†standard_audioç›®å½•ä¸‹çš„WAVæ–‡ä»¶"""
    if audio_dir is None:
        audio_dir = Path(BASE_DIR) / "audio_files" / "standard_audio"
    else:
        audio_dir = Path(audio_dir).resolve()
    
    print("=" * 80)
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†ASR + è¯´è¯äººåˆ†å‰²")
    print(f"å¤„ç†ç›®å½•ï¼š{str(audio_dir)}")
    print("=" * 80)
    
    if not audio_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨ï¼š{str(audio_dir)}")
        return
    
    wav_files = [f for f in audio_dir.iterdir() if f.is_file() and f.suffix.lower() == ".wav"]
    if not wav_files:
        print(f"â„¹ï¸ ç›®å½•ä¸‹æ— WAVæ–‡ä»¶ï¼š{str(audio_dir)}")
        return
    
    total = len(wav_files)
    success_count = 0
    for idx, wav_file in enumerate(wav_files):
        print(f"\n[{idx+1}/{total}] å¤„ç†æ–‡ä»¶ï¼š{wav_file.name}")
        result_json = extract_asr_with_speaker_diarization(str(wav_file))
        result = json.loads(result_json)
        if result["success"]:
            success_count += 1
            print(f"âœ… å¤„ç†æˆåŠŸï¼š{wav_file.name}")
        else:
            print(f"âŒ å¤„ç†å¤±è´¥ï¼š{result['error'][:200]}...")  # æˆªæ–­é•¿é”™è¯¯ä¿¡æ¯
    
    print("\n" + "=" * 80)
    print(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ | æ€»æ•°ï¼š{total} | æˆåŠŸï¼š{success_count} | å¤±è´¥ï¼š{total - success_count}")
    print(f"ğŸ“ ç»“æœä¿å­˜ç›®å½•ï¼š{ASR_OUTPUT_ROOT}")
    print("=" * 80)

# ====================== æµ‹è¯•å‡½æ•° ======================
def test_asr_diarization():
    """æµ‹è¯•å•ä¸ªéŸ³é¢‘æ–‡ä»¶"""
    test_audio_path = Path(BASE_DIR) / "audio_files" / "standard_audio" / "LA_E_1000147.wav"
    test_audio_path_str = str(test_audio_path)

    print("=" * 80)
    print(f"ğŸ§ å¼€å§‹ ASR + è¯´è¯äººåˆ†ç¦»æµ‹è¯•")
    print(f"é¡¹ç›®æ ¹ç›®å½•ï¼ˆæ¥è‡ª.envï¼‰ï¼š{BASE_DIR}")
    print(f"éŸ³é¢‘è·¯å¾„ï¼š{test_audio_path_str}")
    print("=" * 80)

    result_json = extract_asr_with_speaker_diarization(
        audio_path=test_audio_path_str,
        whisper_model_size="base"
    )

    print("ğŸ“„ ASR + Diarization ç»“æœï¼ˆJSONï¼‰ï¼š")
    print(result_json)
    print("=" * 80)

    result = json.loads(result_json)
    if not result["success"]:
        print(f"âŒ æµ‹è¯•å¤±è´¥ï¼š{result['error'][:300]}...")
        return

    print("âœ… æµ‹è¯•æˆåŠŸï¼å…³é”®ä¿¡æ¯å¦‚ä¸‹ï¼š")
    print(f"   - éŸ³é¢‘æ–‡ä»¶åï¼š{result['audio_filename']}")
    print(f"   - è¯­è¨€ï¼š{result['language']}")
    print(f"   - éŸ³é¢‘æ—¶é•¿ï¼š{result['audio_duration']} ç§’")
    print(f"   - æ€»è¯æ•°ï¼š{result['total_words']}")
    print(f"   - è¯´è¯äººæ•°é‡ï¼š{result['total_speakers']}")
    print(f"   - ä½¿ç”¨è®¾å¤‡ï¼š{result['device_used']}")  # æ–°å¢ï¼šæ˜¾ç¤ºä½¿ç”¨çš„è®¾å¤‡
    print("-" * 80)

    preview_n = min(20, len(result["segments"]))
    print(f"ğŸ§© å‰ {preview_n} ä¸ªè¯ï¼ˆå« speaker å¯¹é½ï¼‰ï¼š")
    for i in range(preview_n):
        seg = result["segments"][i]
        print(f"[{seg['start']:>6.2f}s - {seg['end']:>6.2f}s] {seg['speaker_id']}: {seg['word']}")

    json_save_path = Path(ASR_OUTPUT_ROOT) / f"{result['audio_filename']}_asr_diarization.json"
    print("=" * 80)
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜è‡³ï¼š{str(json_save_path)}")
    print("ğŸ‰ ASR + Speaker Diarization æµ‹è¯•å®Œæˆ")

# ====================== ä¸»å…¥å£ ======================
if __name__ == "__main__":
    print(f"ğŸ“Œ é¡¹ç›®æ ¹ç›®å½•ï¼ˆæ¥è‡ª.envï¼‰: {BASE_DIR}")
    # é€‰æ‹©1ï¼šæµ‹è¯•å•ä¸ªæ–‡ä»¶
    test_asr_diarization()
    # é€‰æ‹©2ï¼šæ‰¹é‡å¤„ç†æ‰€æœ‰æ ‡å‡†åŒ–éŸ³é¢‘
    # batch_process_standard_audio()